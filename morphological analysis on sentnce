import nltk
from nltk.tokenize import word_tokenize
from nltk import pos_tag

nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')

sentence = "Unhappily, she ran quickly"

# Tokenize the sentence into words
words = word_tokenize(sentence)

# Perform part-of-speech tagging
pos_tags = pos_tag(words)

print("Tokenized words:", words)
print("Part-of-speech tags:", pos_tags)
